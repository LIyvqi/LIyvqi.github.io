<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>深度学习花书（4）-多层感知机下</title>
      <link href="/2022/06/16/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%8A%B1%E4%B9%A6%EF%BC%884%EF%BC%89-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E4%B8%8B/"/>
      <url>/2022/06/16/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%8A%B1%E4%B9%A6%EF%BC%884%EF%BC%89-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E4%B8%8B/</url>
      
        <content type="html"><![CDATA[<p><a href="https://zh.d2l.ai/chapter_multilayer-perceptrons/kaggle-house-price.html">https://zh.d2l.ai/chapter_multilayer-perceptrons/kaggle-house-price.html</a></p><p>这是天池竞赛的放假预测的实例，一个广泛的用于练手的项目，数据集处理占了大头😂，参考的链接见上，下面是详细的代码。</p><pre><code class="python">import hashlibimport osimport tarfileimport zipfileimport requests#@saveDATA_HUB = dict()DATA_URL = &#39;http://d2l-data.s3-accelerate.amazonaws.com/&#39;def download(name, cache_dir = os.path.join(&#39;..&#39;, &#39;data&#39;)):    &quot;&quot;&quot;下载一个DATA_HUB中的文件，返回本地文件名&quot;&quot;&quot;    assert name in DATA_HUB, f&quot;&#123;name&#125; 不存在于 &#123;DATA_HUB&#125;&quot;    url, sha1_hash = DATA_HUB[name]    os.makedirs(cache_dir, exist_ok=True)    fname = os.path.join(cache_dir, url.split(&#39;/&#39;)[-1])    if os.path.exists(fname):        sha1 = hashlib.sha1()        with open(fname, &#39;rb&#39;) as f:            while True:                data = f.read(1048576)                if not data:                    break                sha1.update(data)        if sha1.hexdigest() == sha1_hash:            return fname  # 命中缓存    print(f&#39;正在从&#123;url&#125;下载&#123;fname&#125;...&#39;)    r = requests.get(url, stream=True, verify=True)    with open(fname, &#39;wb&#39;) as f:        f.write(r.content)    return fname# 下面还有实现两个函数，一个将下载并解压缩一个zip或tar文件，# 另一个是将本书中使用的所有数据集从DATA_HUB下载到缓存目录中。def download_extract(name, folder=None):  #@save    &quot;&quot;&quot;下载并解压zip/tar文件&quot;&quot;&quot;    fname = download(name)    base_dir = os.path.dirname(fname)    data_dir, ext = os.path.splitext(fname)    if ext == &#39;.zip&#39;:        fp = zipfile.ZipFile(fname, &#39;r&#39;)    elif ext in (&#39;.tar&#39;, &#39;.gz&#39;):        fp = tarfile.open(fname, &#39;r&#39;)    else:        assert False, &#39;只有zip/tar文件可以被解压缩&#39;    fp.extractall(base_dir)    return os.path.join(base_dir, folder) if folder else data_dirdef download_all():  #@save    &quot;&quot;&quot;下载DATA_HUB中的所有文件&quot;&quot;&quot;    for name in DATA_HUB:        download(name)%matplotlib inlineimport numpy as npimport pandas as pdimport torchfrom torch import nnfrom d2l import torch as d2l# 下载并缓存数据集DATA_HUB[&#39;kaggle_house_train&#39;] = (  #@save    DATA_URL + &#39;kaggle_house_pred_train.csv&#39;,    &#39;585e9cc93e70b39160e7921475f9bcd7d31219ce&#39;)DATA_HUB[&#39;kaggle_house_test&#39;] = (  #@save    DATA_URL + &#39;kaggle_house_pred_test.csv&#39;,    &#39;fa19780a7b011d9b009e8bff8e99922a8ee2eb90&#39;)train_data = pd.read_csv(download(&#39;kaggle_house_train&#39;))test_data = pd.read_csv(download(&#39;kaggle_house_test&#39;))# 上述是完成了数据的加载，核心的模型部分是下面# (在每个样本中，第一个特征是ID，) 这有助于模型识别每个训练样本。 虽然这很方便，但它不携带任何用于预测的信息。 因此，# 在将数据提供给模型之前，(我们将其从数据集中删除)。all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:]))# 若无法获得测试数据，则可根据训练数据计算均值和标准差numeric_features = all_features.dtypes[all_features.dtypes != &#39;object&#39;].indexall_features[numeric_features] = all_features[numeric_features].apply(    lambda x: (x - x.mean()) / (x.std()))# 在标准化数据之后，所有均值消失，因此我们可以将缺失值设置为0all_features[numeric_features] = all_features[numeric_features].fillna(0)# “Dummy_na=True”将“na”（缺失值）视为有效的特征值，并为其创建指示符特征all_features = pd.get_dummies(all_features, dummy_na=True)  # 离散值使用独热编码all_features.shape</code></pre>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 多层感知机 </tag>
            
            <tag> 房价预测 </tag>
            
            <tag> kaggle实例 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习花书(3)-多层感知机上</title>
      <link href="/2022/06/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%8A%B1%E4%B9%A6-3-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E4%B8%8A/"/>
      <url>/2022/06/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%8A%B1%E4%B9%A6-3-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E4%B8%8A/</url>
      
        <content type="html"><![CDATA[<p>多层感知机算是深度神经网络的入门开始，参考资料：<a href="https://zh.d2l.ai/chapter_multilayer-perceptrons/index.html">https://zh.d2l.ai/chapter_multilayer-perceptrons/index.html</a></p><h3 id="0、不熟悉的一些核心代码"><a href="#0、不熟悉的一些核心代码" class="headerlink" title="0、不熟悉的一些核心代码"></a>0、不熟悉的一些核心代码</h3><pre><code class="python"># 清除以前的梯度,代码x.grad.data.zero_()# 设置为可训练的可求导的参数W1 = nn.Parameter(torch.randn(num_inputs, num_hiddens, requires_grad=True) * 0.01)# 通过API实现多层感知机，这算是最简单的深度学习了吧# 导入包import torchfrom torch import nnfrom d2l import torch as d2l# 模型net = nn.Sequential(nn.Flatten(),                    nn.Linear(784, 256),                    nn.ReLU(),                    nn.Linear(256, 10))# 初始化参数                    def init_weights(m):    if type(m) == nn.Linear:        nn.init.normal_(m.weight, std=0.01)net.apply(init_weights)batch_size, lr, num_epochs = 256, 0.1, 10loss = nn.CrossEntropyLoss(reduction=&#39;none&#39;)trainer = torch.optim.SGD(net.parameters(), lr=lr)train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)# 为了在取对数时进一步稳定该值，将小于1的值设置为1# torch.clamp()就是把数值的区间限制在给定的区间之间clipped_preds = torch.clamp(net(features), 1, float(&#39;inf&#39;))# pandas处理数据的一段代码# 若无法获得测试数据，则可根据训练数据计算均值和标准差numeric_features = all_features.dtypes[all_features.dtypes != &#39;object&#39;].indexall_features[numeric_features] = all_features[numeric_features].apply(    lambda x: (x - x.mean()) / (x.std()))# 在标准化数据之后，所有均值消失，因此我们可以将缺失值设置为0all_features[numeric_features] = all_features[numeric_features].fillna(0)</code></pre><p><code>DataFrame</code> 有一个方便的 <code>dtypes</code> 属性用于返回一个包含每个列的数据类型的序列，</p><p><em>训练误差</em>（training error）是指， 模型在训练数据集上计算得到的误差。 <em>泛化误差</em>（generalization error）是指， 模型应用在同样从原始样本的分布中抽取的无限多数据样本时，模型误差的期望。</p><h2 id="1、K折交叉验证"><a href="#1、K折交叉验证" class="headerlink" title="1、K折交叉验证"></a>1、K折交叉验证</h2><p>​当训练数据稀缺时，我们甚至可能无法提供足够的数据来构成一个合适的验证集。 这个问题的一个流行的解决方案是采用<strong>𝐾</strong><em><strong>折交叉验证</strong></em>。 这里，原始训练数据被分成𝐾个不重叠的子集。 然后执行K次模型训练和验证，每次在𝐾−1个子集上进行训练， 并在剩余的一个子集（在该轮中没有用于训练的子集）上进行验证。 最后，<strong>通过对𝐾次实验的结果取平均来估计训练和验证误差</strong>。</p><h2 id="2、过拟合和欠拟合"><a href="#2、过拟合和欠拟合" class="headerlink" title="2、过拟合和欠拟合"></a>2、过拟合和欠拟合</h2><p>判断：</p><p>1、训练误差和验证误差都很严重， 但它们之间仅有一点差距。 如果模型不能降低训练误差，这可能意味着模型过于简单，欠拟合。</p><p>2、训练误差明显低于验证误差时要小心， 这表明严重的<em>过拟合</em>（overfitting），但是最好的预测模型在训练数据上的表现往往比在保留（验证）数据上好得多。 最终，我们通常更关心验证误差。</p><p>解决过拟合的方法：</p><p>1、限制特征的数量（例如拟合时调整阶数）</p><p>2、参数的权重衰减（范数）。使用L2范数的一个原因是它对权重向量的大分量施加了巨大的惩罚。 这使得我们的学习算法偏向于在大量特征上均匀分布权重的模型。 在实践中，这可能使它们对单个变量中的观测误差更为稳定。 相比之下，L1惩罚会导致模型将权重集中在一小部分特征上， 而将其他权重清除为零。 这称为<em>特征选择</em>（feature selection），这可能是其他场景下需要的。</p><p>pytorch中集成了权重衰减的代码</p><p>在实例化优化器时直接通过<code>weight_decay</code>指定weight decay超参数。 默认情况下，PyTorch同时衰减权重和偏移。 这里我们只为权重设置了<code>weight_decay</code>，所以偏置参数𝑏不会衰减。</p><pre><code class="Plain">net = nn.Sequential(nn.Linear(num_inputs, 1))for param in net.parameters():    param.data.normal_()loss = nn.MSELoss(reduction=&#39;none&#39;)num_epochs, lr = 100, 0.003# 偏置参数没有衰减trainer = torch.optim.SGD([    &#123;&quot;params&quot;:net[0].weight,&#39;weight_decay&#39;: wd&#125;,    &#123;&quot;params&quot;:net[0].bias&#125;], lr=lr)</code></pre><h2 id="3、Dropout"><a href="#3、Dropout" class="headerlink" title="3、Dropout"></a>3、Dropout</h2><pre><code class="Python">实现dropout的两行核心代码，X是输入的特征mask = (torch.rand(X.shape) &gt; dropout).float()  # 直接在每一个位置都转为了0或1return mask * X / (1.0 - dropout)在torch中是有集成的torch.nn.Dropout(0.3)</code></pre><h2 id="4、梯度消失和梯度爆炸"><a href="#4、梯度消失和梯度爆炸" class="headerlink" title="4、梯度消失和梯度爆炸"></a>4、梯度消失和梯度爆炸</h2><p>​不稳定梯度带来的风险不止在于数值表示； 不稳定梯度也威胁到我们优化算法的稳定性。 我们可能面临一些问题。 要么是<em>梯度爆炸</em>（gradient exploding）问题： 参数更新过大，破坏了模型的稳定收敛； 要么是<em>梯度消失</em>（gradient vanishing）问题： 参数更新过小，在每次更新时几乎不会移动，导致模型无法学习。</p><p>Sigmoid激活函数经常会遇到梯度消失的问题，如下，所以现在默认选择 relu激活函数</p><img src="https://raw.githubusercontent.com/LIyvqi/FigOfWeb/main/202206152248418.png" alt="img" style="zoom:50%;" /><ul><li><p><strong>在模型的训练和设计中要打破对称性</strong>，在前向传播期间，两个隐藏单元采用相同的输入和参数， 产生相同的激活，该激活被送到输出单元。 在反向传播期间，根据参数𝐖(1)对输出单元进行微分， 得到一个梯度，其元素都取相同的值。 因此，在基于梯度的迭代（例如，小批量随机梯度下降）之后， 𝐖(1)的所有元素仍然采用相同的值。 这样的迭代永远不会打破对称性，我们可能永远也无法实现网络的表达能力。虽然小批量随机梯度下降不会打破这种对称性，但暂退法正则化可以。</p></li><li><ul><li>解决上述问题最重要的途径就是参数初始化：</li></ul></li></ul><p>默认初始化：不指定初始化方法， 框架将使用默认的随机初始化方法，对于中等难度的问题，这种方法通常很有效。</p><p>Xavier初始化是在“不存在非线性”的假设中推导出来的，但是实践中的效果非常好。对于每一层，输出的方差不受输入数量的影响，任何梯度的方差不受输出数量的影响。</p><p><img src="https://raw.githubusercontent.com/LIyvqi/FigOfWeb/main/202206152248441.png" alt="img"></p><p>python中assert的使用： </p><pre><code class="Python">import sysassert (&#39;linux&#39; in sys.platform), &quot;该代码只能在 Linux 下执行&quot;# 如果assert后面的为True，下面的代码正常执行，如果不是，触发异常并抛出# 接下来要执行的代码</code></pre>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 多层感知机 </tag>
            
            <tag> 过（欠）拟合 </tag>
            
            <tag> 梯度消失和爆炸 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习花书(2)-逻辑回归</title>
      <link href="/2022/06/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%8A%B1%E4%B9%A6-2-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
      <url>/2022/06/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%8A%B1%E4%B9%A6-2-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/</url>
      
        <content type="html"><![CDATA[<p><a href="https://zh.d2l.ai/chapter_linear-networks/index.html">https://zh.d2l.ai/chapter_linear-networks/index.html</a></p><p>参考资料如上</p><pre><code class="Plain">def sgd(params, lr, batch_size):  #@save  sgd的具体实现    &quot;&quot;&quot;小批量随机梯度下降&quot;&quot;&quot;    # torch.no_grad() 是一个上下文管理器，被该语句 wrap 起来的部分将不会track 梯度    with torch.no_grad():          for param in params:            param -= lr * param.grad / batch_size            param.grad.zero_()# 实际训练的过程for epoch in range(num_epochs):    for X, y in data_iter(batch_size, features, labels):        l = loss(net(X, w, b), y)  # X和y的小批量损失        # 因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起，        # 并以此计算关于[w,b]的梯度        l.sum().backward()        sgd([w, b], lr, batch_size)  # 使用参数的梯度更新参数# 上述是手动实现的核心代码，如果通过torch实现非常简单import numpy as npimport torchfrom torch.utils import datafrom d2l import torch as d2ltrue_w = torch.tensor([2, -3.4])true_b = 4.2features, labels = d2l.synthetic_data(true_w, true_b, 1000)def load_array(data_arrays, batch_size, is_train=True):  #@save    &quot;&quot;&quot;构造一个PyTorch数据迭代器&quot;&quot;&quot;    dataset = data.TensorDataset(*data_arrays)    return data.DataLoader(dataset, batch_size, shuffle=is_train)batch_size = 10data_iter = load_array((features, labels), batch_size)# nn是神经网络的缩写from torch import nnnet = nn.Sequential(nn.Linear(2, 1))# 我们通过`net[0]`选择网络中的第一个图层，然后使用`weight.data`和`bias.data`方法访问参数。# 我们还可以使用替换方法`normal_`和`fill_`来重写参数值。net[0].weight.data.normal_(0, 0.01),net[0].bias.data.fill_(0)loss = nn.MSELoss() # 定义损失函数trainer = torch.optim.SGD(net.parameters(), lr=0.03)# 训练num_epochs = 3for epoch in range(num_epochs):    for X, y in data_iter:        l = loss(net(X) ,y)        trainer.zero_grad()        l.backward()        trainer.step()    l = loss(net(features), labels)    print(f&#39;epoch &#123;epoch + 1&#125;, loss &#123;l:f&#125;&#39;)w = net[0].weight.dataprint(&#39;w的估计误差：&#39;, true_w - w.reshape(true_w.shape))b = net[0].bias.dataprint(&#39;b的估计误差：&#39;, true_b - b)</code></pre><p>逻辑回归，图像分类</p><pre><code class="Python">def get_dataloader_workers():  #@save    &quot;&quot;&quot;使用4个进程来读取数据&quot;&quot;&quot;    return 4train_iter = data.DataLoader(mnist_train, batch_size, shuffle=True,                             num_workers=get_dataloader_workers())# 准确率指标的计算def accuracy(y_hat, y):  #@save    &quot;&quot;&quot;计算预测正确的数量&quot;&quot;&quot;    if len(y_hat.shape) &gt; 1 and y_hat.shape[1] &gt; 1:        y_hat = y_hat.argmax(axis=1)    cmp = y_hat.type(y.dtype) == y    return float(cmp.type(y.dtype).sum())# 交叉熵的实现def cross_entropy(y_hat, y):    return - torch.log(y_hat[range(len(y_hat)), y])  </code></pre><p>softmax回归的简洁版本实现</p><pre><code class="Python">import torchfrom torch import nnfrom d2l import torch as d2lbatch_size = 256train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)# PyTorch不会隐式地调整输入的形状。因此，# 我们在线性层前定义了展平层（flatten），来调整网络输入的形状net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10))def init_weights(m):    if type(m) == nn.Linear:        nn.init.normal_(m.weight, std=0.01)net.apply(init_weights);loss = nn.CrossEntropyLoss(reduction=&#39;none&#39;)trainer = torch.optim.SGD(net.parameters(), lr=0.1)num_epochs = 10d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)</code></pre><p>pytorch的任何网络<code>net</code>，都是<code>torch.nn.Module</code>的子类,都算是<code>module</code>，也就是模块。pytorch中的<code>model.apply(fn)</code>会递归地将函数<code>fn</code>应用到父模块的每个子模块<code>submodule</code>，也包括<code>model</code>这个父模块自身。</p><p>对于net.apply()，将一个函数fn递归地应用到模块自身以及该模块的每一个子模块(即在函数.children()中返回的子模块).该方法通常用来初始化一个模型中的参数(另见torch-nn-init部分的内容).</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 逻辑回归 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2022年老婆生日快乐</title>
      <link href="/2022/06/13/2022%E5%B9%B4%E8%80%81%E5%A9%86%E7%94%9F%E6%97%A5%E5%BF%AB%E4%B9%90/"/>
      <url>/2022/06/13/2022%E5%B9%B4%E8%80%81%E5%A9%86%E7%94%9F%E6%97%A5%E5%BF%AB%E4%B9%90/</url>
      
        <content type="html"><![CDATA[<h2 id="祝我亲爱的老婆生日快乐"><a href="#祝我亲爱的老婆生日快乐" class="headerlink" title="祝我亲爱的老婆生日快乐"></a>祝我亲爱的老婆生日快乐</h2><p>你是我遥望的一颗星星</p><p>繁星暗淡 只望见你</p><p>不知所以 更想你</p><p>想留住你 想拥抱你</p><p>擦亮银河 照亮你</p><pre><code>等我去找你哦，一起过一个快快乐乐的生日！</code></pre><p>  <img src="https://raw.githubusercontent.com/LIyvqi/FigOfWeb/main/202206132215420.png" alt="我最美"> </p> <img src="https://raw.githubusercontent.com/LIyvqi/FigOfWeb/main/202206132215199.png" alt="我最可爱" style="zoom: 80%;" /><p> <img src="https://raw.githubusercontent.com/LIyvqi/FigOfWeb/main/202206132216651.png" alt="一直幸福哦"> </p>]]></content>
      
      
      <categories>
          
          <category> Love </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 老婆生日 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习花书-预备知识</title>
      <link href="/2022/06/13/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%8A%B1%E4%B9%A6Day1-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"/>
      <url>/2022/06/13/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%8A%B1%E4%B9%A6Day1-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/</url>
      
        <content type="html"><![CDATA[<h2 id="0、写在最前面"><a href="#0、写在最前面" class="headerlink" title="0、写在最前面"></a>0、写在最前面</h2><p>​计划重新学习一下深度学习这本书的内容，我选择的是李沐老师翻译的部分，开源在网站中，可以见文末，计划一个月内学完，并且把不熟悉的部分整理一下，因为之前也是有些基础的，此教程是我在闲暇时间查漏补缺的内容，个人主观性较强，但是学习路线很明确，欢迎大家一起学习~</p><h2 id="1、pandas"><a href="#1、pandas" class="headerlink" title="1、pandas"></a>1、pandas</h2><pre><code class="Python"># pandas按照位置读取和缺失值的处理# data.iloc[]  中括号， fillna 缺失值的填充inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]inputs = inputs.fillna(inputs.mean())inputs = pd.get_dummies(inputs, dummy_na=True)    # get_dummies是自动将文字型转化为数值型x.shape    # 没有括号，张量的形状A = torch.arange(20, dtype=torch.float32).reshape(5, 4)B = A.clone()  # 通过分配新内存，将A的一个副本分配给B2+A   #将张量乘以或加上一个标量不会改变张量的形状，其中张量的每个元素都将与标量相加或相乘# 在tensor中，是面向对象来进行最大最小值的求解的A.sum()sum_A = A.sum(axis=1, keepdims=True) #在调用函数来[计算总和或均值时保持轴数不变]会很有用# axis=0的时候一般是沿着向下的方法，axis=1的时候沿着横轴的方法# 矩阵的向量积A.shape, x.shape, torch.mv(A, x) # (torch.Size([5, 4]), torch.Size([4]), tensor([ 12.,  44.,  76., 108., 140.]))# 矩阵的乘法torch.mm(A, B)# torch求二范数和一范数torch.norm(u),torch.abs(u).sum()</code></pre><h2 id="微积分"><a href="#微积分" class="headerlink" title="微积分"></a>微积分</h2><pre><code class="Python"># 自动求导求梯度的例子import torchx = torch.arange(4.0)x.requires_grad_(True)# 等价于x=torch.arange(4.0,requires_grad=True)x.grad  # 默认值是Noney = 2 * torch.dot(x, x)y.backward()x.grad    # tensor([ 0.,  4.,  8., 12.])   x.grad == 4 * x   # tensor([True, True, True, True])# 在默认情况下，PyTorch会累积梯度，我们需要清除之前的值x.grad.zero_()y = x.sum()y.backward()x.gradx.grad_zero() #tensor([0., 1., 2., 3.], requires_grad=True)  清理了梯度，回到之前</code></pre><h2 id="概率及采样"><a href="#概率及采样" class="headerlink" title="概率及采样"></a>概率及采样</h2><pre><code class="Python">from torch.distributions import multinomialfair_probs = torch.ones([6]) / 6# 将结果存储为32位浮点数以进行除法counts = multinomial.Multinomial(1000, fair_probs).sample() #它在索引𝑖i处的值是采样结果中𝑖i出现的次数counts / 1000  # 相对频率作为估计值# 上述就是按照fair_probs的概率模拟抽样import torchprint(dir(torch.distributions))# 查看torch中distributions里面内置的函数help(torch.ones)    # 查看具体的用法</code></pre><h2 id="笔记出处—完整教程"><a href="#笔记出处—完整教程" class="headerlink" title="笔记出处—完整教程"></a>笔记出处—完整教程</h2><p><a href="https://zh.d2l.ai/chapter_preliminaries/index.html">https://zh.d2l.ai/chapter_preliminaries/index.html</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 预备知识 </tag>
            
            <tag> 微积分 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo写博客中会遇到的问题（持续更新）</title>
      <link href="/2022/06/12/Hexo%E5%86%99%E5%8D%9A%E5%AE%A2%E4%B8%AD%E4%BC%9A%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%88%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0%EF%BC%89/"/>
      <url>/2022/06/12/Hexo%E5%86%99%E5%8D%9A%E5%AE%A2%E4%B8%AD%E4%BC%9A%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%88%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h2 id="1、白嫖飞书的图床"><a href="#1、白嫖飞书的图床" class="headerlink" title="1、白嫖飞书的图床"></a>1、白嫖飞书的图床</h2><p>​因为学校一直用飞书，之前经常在飞书云文档记笔记，我发现在飞书云文档上传照片的时候，直接复制到.md文件中复制过来的居然是图床的链接，那这样只要飞书的文件不删除，就可以一直白嫖了，哈哈哈哈。</p><p>​过了一天之后发现飞书得到图床居然是动态更新的，第二天就用不了了，无语啊。后来我又改成了Github的仓库做图床。</p><p>​下载PicGo软件，找到图床设置，选择Github的图床就行。</p><img src="https://raw.githubusercontent.com/LIyvqi/FigOfWeb/main/image-20220612233642481.png" alt="image-20220612233642481" style="zoom:50%;" /><img src="https://raw.githubusercontent.com/LIyvqi/FigOfWeb/main/image-20220612233822432.png" alt="image-20220612233822432" style="zoom: 25%;" /><p>在typora的偏好设置中也选择，这样以后直接复制到typora中的照片就可以，不用管别的了。</p><p>​但是考虑到GitHub的存储空间是有限的，只有1个G，之后就没了，后来发现了 又拍云 这个网站，就在我的首页有跳转链接，直接百度搜索就行，比较容易。</p><p>​又拍云有一个活动，每年免费送一次空间和流量，只需要在网站的主页上放上他的广告即可。</p><p><a href="https://www.upyun.com/league">https://www.upyun.com/league</a>     进入此网站，按照教程申请即可。</p><img src="http://liyuqi-image.test.upcdn.net/202206131927395.png" alt="image-20220613192711265" style="zoom:25%;" /> <h2 id="2、报错问题-SSH连接的443"><a href="#2、报错问题-SSH连接的443" class="headerlink" title="2、报错问题 SSH连接的443"></a>2、报错问题 SSH连接的443</h2><p>​写好了博客上传的时候总是会出现连接超时 port 443： Timed out和OpenSSL错误的问题，教程的很多方法都不太好，直接改掉根目录配置文件_config.yml的deploy这部分。</p><pre><code>deploy:  type: git  repository: git@github.com:YOURNAME.github.io.git # 把https的协议换成git的，可以去仓库看  branch: main</code></pre>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 写作 </tag>
            
            <tag> 问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo-GitHub配置个人网站</title>
      <link href="/2022/06/12/Hexo-GitHub%E9%85%8D%E7%BD%AE%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/"/>
      <url>/2022/06/12/Hexo-GitHub%E9%85%8D%E7%BD%AE%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/</url>
      
        <content type="html"><![CDATA[<p>参考：<a href="https://www.bilibili.com/video/BV1mU4y1j72n?spm_id_from=333.999.0.0">【2021最新版】保姆级Hexo+github搭建个人博客_哔哩哔哩_bilibili</a></p><p>比着视频来一遍，非常简单，视频大约30min，实操1小时就ok，整个教程都非常顺利，没有任何bug。</p><h2 id="1、工具的安装"><a href="#1、工具的安装" class="headerlink" title="1、工具的安装"></a>1、工具的安装</h2><p>需要安装 <a href="https://www.cnblogs.com/zhouyu2017/p/6485265.html">Node.js安装及环境配置之Windows篇 - 周瑜周 - 博客园</a>，把这些工具都安装成果之后查看是否ok。</p><p>node -v</p><p>npm -v</p><p>git –version</p><p>hexo -v</p><h2 id="2、创建自己的Github仓库"><a href="#2、创建自己的Github仓库" class="headerlink" title="2、创建自己的Github仓库"></a>2、创建自己的Github仓库</h2><p>在创建仓库的时候，一定要把仓库命名为<a href="https://github.com/LIyvqi/LIyvqi.github.io">LIyvqi.github.i</a>o  LIyvqi是我的github用户名。</p><h2 id="3、生成SSH的密钥并绑定"><a href="#3、生成SSH的密钥并绑定" class="headerlink" title="3、生成SSH的密钥并绑定"></a>3、生成SSH的密钥并绑定</h2><p>一般正常用GitHub的电脑都没问题，哈哈哈，这一步可以跳过。</p><p>在一个文件夹中打开gitbash，命令行中输入 ssh:ssh-keygen -t rsa -C “邮箱地址”</p><p>.ssh生成路径：C:\Users\自己的用户名.ssh</p><p><strong>可以上来就直接测试。</strong></p><p>测定ssh是否绑定成功：ssh -T <a href="mailto:&#x67;&#x69;&#x74;&#64;&#103;&#105;&#116;&#x68;&#x75;&#x62;&#46;&#99;&#x6f;&#109;">&#x67;&#x69;&#x74;&#64;&#103;&#105;&#116;&#x68;&#x75;&#x62;&#46;&#99;&#x6f;&#109;</a></p><p>如果一直出现ssh: connect to host github.com port 22: Connection refused的话具体看这个教程<a href="https://www.cnblogs.com/Archer314/p/14641310.html">https://www.cnblogs.com/Archer314/p/14641310.html</a> </p><h2 id="4、初始化博客"><a href="#4、初始化博客" class="headerlink" title="4、初始化博客"></a>4、初始化博客</h2><p>新建一个文件夹，选择合适的位置，这就是你日后写博客的本地文件了，进入这个文件后，打开gitbash，输入命令行：</p><p>hexo init      #初始化hexo博客</p><p>如果报错SyntaxError: Unexpected token …</p><p>建议更新一下node.js版本</p><p>hexo s    #静态生成</p><h2 id="5、把本地的博客传到github上，就可以直接当作网站打开了"><a href="#5、把本地的博客传到github上，就可以直接当作网站打开了" class="headerlink" title="5、把本地的博客传到github上，就可以直接当作网站打开了"></a>5、把本地的博客传到github上，就可以直接当作网站打开了</h2><p>配置文件修改(_config.yml)，就在当前文件夹下</p><p><img src="https://raw.githubusercontent.com/LIyvqi/FigOfWeb/main/image-20220612233348720.png" alt="image-20220612233348720"></p><p>（：后面有个空格）</p><p>deploy:</p><p> type: git</p><p> repository: <a href="https://github.com/%E4%BD%A0%E7%9A%84%E5%90%8D%E5%AD%97/%E4%BB%93%E5%BA%93%E7%9A%84%E5%90%8D%E5%AD%97.git">https://github.com/你的名字/仓库的名字.git</a></p><p> branch: 分支</p><p>之后在gitbash命令行中输入：npm install hexo-deployer-git –save</p><p>这样就安装好了hexo-deployer-git自动部署发布工具。</p><p>上述就是使用hexo搭建一个个人博客的教程，自定义域名还要花钱买，我们白嫖了哦，就用这个吧，可以在网络上访问，直接输入 <a href="https://liyvqi.github.io/">https://liyvqi.github.io/</a> </p><h2 id="6、更换主题"><a href="#6、更换主题" class="headerlink" title="6、更换主题"></a>6、更换主题</h2><p>在上面新建的那个web文件夹下，git bash复制命令行下载新的主题以及更新即可。</p><p><img src="https://raw.githubusercontent.com/LIyvqi/FigOfWeb/main/image-20220612233434657.png" alt="image-20220612233434657"></p><p>之后把_config.yml中的theme换成3-hexo</p><p>再之后选择更新：</p><pre><code class="Plain">cd themes/3-hexogit pull</code></pre><p>返回到MyWeb目录之后，输入   hexo server查看本地的主题是否已经换了。</p><p>如果配置了Github之后，可以输入以下命令提交修改后的主题博客。</p><pre><code class="Plain">hexo clean &amp;&amp; hexo g &amp;&amp; hexo d</code></pre><p>我做的时候出线了本地主题换了，但是GitHub上没有，有延迟的问题，等一会儿就好了。</p><h2 id="7、网站内容修改"><a href="#7、网站内容修改" class="headerlink" title="7、网站内容修改"></a>7、网站内容修改</h2><p>更换了主题之后，这个网站的格式内容什么的，都是在下面这个文件夹下</p><p>D:\MyBlog\MyWeb\themes\3-hexo</p><p>一些细节什么的，可以先改_config.yml   里面的注释比较齐全，可以改成自己的了。</p><h2 id="8、发文章和删除文章"><a href="#8、发文章和删除文章" class="headerlink" title="8、发文章和删除文章"></a>8、发文章和删除文章</h2><pre><code class="Plain">hexo new &quot;文章名&quot;找到那个.md文件开始写文章，写完了之后，可以hexo s本地查看，之后直接执行下面命令提交就行。hexo d# 删除的时候，在文件夹里面删了，之后执行hexo d</code></pre><h2 id="9、修改博客的报错问题"><a href="#9、修改博客的报错问题" class="headerlink" title="9、修改博客的报错问题"></a>9、修改博客的报错问题</h2><p>一般更改的时候除了改博客，还改一些别的，这时候会报错（spawn failed），是因为git或者hexo d的时候改变了一些.deploy_git文件下的内容，最简单粗暴的办法就是删了重来。</p><pre><code class="Plain">删除.deploy_git文件夹;输入git config --global core.autocrlf false然后，依次执行：hexo cleanhexo ghexo d</code></pre><h2 id="最后的进阶"><a href="#最后的进阶" class="headerlink" title="最后的进阶"></a>最后的进阶</h2><p><a href="http://yearito.cn/posts/hexo-writing-skills.html#Sublime-Text-3">http://yearito.cn/posts/hexo-writing-skills.html#Sublime-Text-3</a></p><p>写作的教程，可以参考上面</p>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 教程 </tag>
            
            <tag> 建站 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World(作者自带的，感谢作者，就不删啦)</title>
      <link href="/2022/06/12/hello-world/"/>
      <url>/2022/06/12/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre><code class="bash">$ hexo new &quot;My New Post&quot;</code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre><code class="bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre><code class="bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre><code class="bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
