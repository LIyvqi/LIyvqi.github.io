<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>2022届的学长学姐毕业快乐-俺研一</title>
      <link href="/2022/06/19/2022%E5%B1%8A%E7%9A%84%E5%AD%A6%E9%95%BF%E5%AD%A6%E5%A7%90%E6%AF%95%E4%B8%9A%E5%BF%AB%E4%B9%90-%E4%BF%BA%E7%A0%94%E4%B8%80/"/>
      <url>/2022/06/19/2022%E5%B1%8A%E7%9A%84%E5%AD%A6%E9%95%BF%E5%AD%A6%E5%A7%90%E6%AF%95%E4%B8%9A%E5%BF%AB%E4%B9%90-%E4%BF%BA%E7%A0%94%E4%B8%80/</url>
      
        <content type="html"><![CDATA[<p>​我才上研一，居然经历了两次毕业了，每次毕业前在工作上总会那么小小的摆烂几天好好，感谢实验室的学长学姐们对我这个废物码农的帮助！新冠三年，没有凑出一张完整的大合照，唉，** 的新冠病毒，退退退！！</p><blockquote><p>书上说，天下没有不散的宴席；不要怕，书上还说，人生何处不相逢。</p></blockquote><p><img src="https://raw.githubusercontent.com/LIyvqi/FigOfWeb/main/202206192200352.png" alt="郭某">  </p><p><img src="https://raw.githubusercontent.com/LIyvqi/FigOfWeb/main/202206192150070.png" alt="顿某">  </p>]]></content>
      
      
      <categories>
          
          <category> Love </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 毕业 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习花书(6)-卷积神经网络</title>
      <link href="/2022/06/19/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%8A%B1%E4%B9%A6-6-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2022/06/19/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%8A%B1%E4%B9%A6-6-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h2 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h2><p>本节介绍构成所有卷积网络主干的基本元素。 这包括卷积层本身、填充（padding）和步幅（stride）的基本细节、用于在相邻区域汇聚信息的汇聚层（pooling）、在每一层中多通道（channel）的使用，以及有关现代卷积网络架构的仔细讨论。</p><p><a href="https://zh.d2l.ai/chapter_convolutional-neural-networks/index.html">https://zh.d2l.ai/chapter_convolutional-neural-networks/index.html</a></p><h3 id="5-1、写在最前面，不熟悉的代码"><a href="#5-1、写在最前面，不熟悉的代码" class="headerlink" title="5.1、写在最前面，不熟悉的代码"></a>5.1、写在最前面，不熟悉的代码</h3><p>要学会调用卷积层和池化层，也要自己会写卷积层和池化层。</p><pre><code class="python">nn.Conv2d()in_channels：输入的通道数目 【必选】out_channels： 输出的通道数目 【必选】kernel_size：卷积核的大小，类型为int 或者元组，当卷积是方形的时候，只需要一个整数边长即可，卷积不是方形，要输入一个元组表示 高和宽。【必选】stride： 卷积每次滑动的步长为多少，默认是 1 【可选】padding： 设置在所有边界增加 值为 0 的边距的大小（也就是在feature map 外围增加几圈 0 ），例如当 padding =1 的时候，如果原来大小为 3 × 3 ，那么之后的大小为 5 × 5 。即在外围加了一圈 0 。【可选】参数的详解出自：https://blog.csdn.net/qq_38863413/article/details/104108808conv2d = nn.Conv2d(1, 1, kernel_size=(5, 3), padding=(2, 1))comp_conv2d(conv2d, X).shapeconv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))comp_conv2d(conv2d, X).shape# 不光填充可以高度和宽度不一样，步幅也可以高度和宽度不一样# 元组里面先高度后宽度torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)kernel_size(int or tuple) ：max pooling的窗口大小stride(int or tuple, optional)：max pooling的窗口移动的步长。默认值是kernel_sizepadding(int or tuple, optional) ：输入的每一条边补充0的层数dilation(int or tuple, optional)：一个控制窗口中元素步幅的参数return_indices ：如果等于True，会返回输出最大值的序号，对于上采样操作会有帮助ceil_mode ：如果等于True，计算输出信号大小的时候，会使用向上取整，代替默认的向下取整的# 打印每一层的形状for layer in net:    X = layer(X)  # 调用网络中的每一层，计算    print(layer.__class__.__name__,&#39;output shape: \t&#39;,X.shape)    # 自己实现一个卷积层(有些面试常问的)def corr2d(X, K):  #@save    &quot;&quot;&quot;计算二维互相关运算，了解即可，后面直接掉包&quot;&quot;&quot;    h, w = K.shape    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))    for i in range(Y.shape[0]):        for j in range(Y.shape[1]):            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()    return Y# 卷积层对输入和卷积核权重进行互相关运算，并在添加标量偏置之后产生输出。 # 所以，卷积层中的两个被训练的参数是卷积核权重和标量偏置。class Conv2D(nn.Module):    def __init__(self, kernel_size):        super().__init__()        self.weight = nn.Parameter(torch.rand(kernel_size))        self.bias = nn.Parameter(torch.zeros(1))    def forward(self, x):        return corr2d(x, self.weight) + self.bias# 高度和宽度分别为ℎh和𝑤w的卷积核可以被称为ℎ×𝑤h×w卷积或ℎ×𝑤h×w卷积核。 # 我们也将带有ℎ×𝑤h×w卷积核的卷积层称为ℎ×𝑤h×w卷积层。</code></pre><h3 id="5-2、卷积介绍"><a href="#5-2、卷积介绍" class="headerlink" title="5.2、卷积介绍"></a>5.2、卷积介绍</h3><p>卷积神经网络正是将<em>空间不变性</em>（spatial invariance）的这一概念系统化，从而基于这个模型使用较少的参数来学习有用的表示。设计适合于计算机视觉的神经网络架构，应具备以下两点：</p><ol><li><p><em>平移不变性</em>（translation invariance）：不管检测对象出现在图像中的哪个位置，神经网络的前面几层应该对相同的图像区域具有相似的反应，即为“平移不变性”。</p></li><li><p><em>局部性</em>（locality）：神经网络的前面几层应该只探索输入图像中的局部区域，而不过度在意图像中相隔较远区域的关系，这就是“局部性”原则。最终，可以聚合这些局部特征，以在整个图像级别进行预测。</p></li></ol><p>严格来说，卷积层是个错误的叫法，因为它所表达的运算其实是<em>互相关运算</em>（cross-correlation），而不是卷积运算。 在卷积层中，输入张量和核张量通过(<strong>互相关运算</strong>)产生输出张量。</p><p>一个卷积核的输出计算：</p><p><img src="https://raw.githubusercontent.com/LIyvqi/FigOfWeb/main/202206192138635.png" alt="img"></p><pre><code class="Python">def corr2d(X, K):  #@save    &quot;&quot;&quot;计算二维互相关运算，了解即可，后面直接掉包&quot;&quot;&quot;    h, w = K.shape    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))    for i in range(Y.shape[0]):        for j in range(Y.shape[1]):            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()    return Y# 卷积层对输入和卷积核权重进行互相关运算，并在添加标量偏置之后产生输出。 # 所以，卷积层中的两个被训练的参数是卷积核权重和标量偏置。class Conv2D(nn.Module):    def __init__(self, kernel_size):        super().__init__()        self.weight = nn.Parameter(torch.rand(kernel_size))        self.bias = nn.Parameter(torch.zeros(1))    def forward(self, x):        return corr2d(x, self.weight) + self.bias# 高度和宽度分别为ℎh和𝑤w的卷积核可以被称为ℎ×𝑤h×w卷积或ℎ×𝑤h×w卷积核。 # 我们也将带有ℎ×𝑤h×w卷积核的卷积层称为ℎ×𝑤h×w卷积层。</code></pre><p>卷积的填充，因为卷积核是一个小卷积，在卷积的过程中会出现输入的规模减小，我们可以对边缘进行填充来减少这个现象。</p><pre><code class="Python"># 请注意，这里每边都填充了1行或1列，因此总共添加了2行或2列conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1) X = torch.rand(size=(8, 8))X = X.reshape((1, 1) + X.shape)  # 这里的（1，1）表示批量大小和通道数都是1Y = conv2d(X)Y.shape  # torch.Size([1, 1, 8, 8])</code></pre><p>nn.Conv2d()</p><pre><code class="Plain">in_channels：输入的通道数目 【必选】out_channels： 输出的通道数目 【必选】kernel_size：卷积核的大小，类型为int 或者元组，当卷积是方形的时候，只需要一个整数边长即可，卷积不是方形，要输入一个元组表示 高和宽。【必选】stride： 卷积每次滑动的步长为多少，默认是 1 【可选】padding： 设置在所有边界增加 值为 0 的边距的大小（也就是在feature map 外围增加几圈 0 ），例如当 padding =1 的时候，如果原来大小为 3 × 3 ，那么之后的大小为 5 × 5 。即在外围加了一圈 0 。【可选】参数的详解出自：https://blog.csdn.net/qq_38863413/article/details/104108808</code></pre><p>当卷积核的高度和宽度不同时，我们可以[<strong>填充不同的高度和宽度</strong>]，使输出和输入具有相同的高度和宽度。在如下示例中，<strong>我们使用高度为5，宽度为3的卷积核，高度和宽度两边的填充分别为2和1。</strong></p><pre><code class="Python">conv2d = nn.Conv2d(1, 1, kernel_size=(5, 3), padding=(2, 1))comp_conv2d(conv2d, X).shapeconv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))comp_conv2d(conv2d, X).shape# 不光填充可以高度和宽度不一样，步幅也可以高度和宽度不一样# 元组里面先高度后宽度</code></pre><p>默认情况下，填充为0，步幅为1。在实践中，我们很少使用不一致的步幅或填充</p><h3 id="5-3、多输入输出通道"><a href="#5-3、多输入输出通道" class="headerlink" title="5.3、多输入输出通道"></a>5.3、多输入输出通道</h3><p>当我们添加通道时，我们的输入和隐藏的表示都变成了三维张量。例如，每个RGB输入图像具有3×ℎ×𝑤的形状。我们将这个大小为3的轴称为<em>通道</em>（channel）维度。</p><p><img src="https://raw.githubusercontent.com/LIyvqi/FigOfWeb/main/202206192138290.png" alt="img"> </p><p>多通道计算的实现</p><pre><code class="Python">X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])def corr2d_multi_in(X, K):    # 先遍历“X”和“K”的第0个维度（通道维度），再把它们加在一起    return sum(d2l.corr2d(x, k) for x, k in zip(X, K))def corr2d_multi_in_out(X, K):    # 迭代“K”的第0个维度，每次都对输入“X”执行互相关运算。    # 最后将所有结果都叠加在一起    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)corr2d_multi_in_out(X, K)</code></pre><h3 id="5-4、Pooling"><a href="#5-4、Pooling" class="headerlink" title="5.4、Pooling"></a>5.4、Pooling</h3><p>双重目的：降低卷积层对位置的敏感性，同时降低对空间降采样表示的敏感性。</p><p>不同于卷积层中的输入与卷积核之间的互相关计算，汇聚层不包含参数。 相反，池运算是确定性的，我们通常计算汇聚窗口中所有元素的最大值或平均值。</p><pre><code class="Python"># 了解即可，一个汇聚层的代码def pool2d(X, pool_size, mode=&#39;max&#39;):    p_h, p_w = pool_size    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))   # 设置输出的窗口的大小    for i in range(Y.shape[0]):        for j in range(Y.shape[1]):            if mode == &#39;max&#39;:                Y[i, j] = X[i: i + p_h, j: j + p_w].max()            elif mode == &#39;avg&#39;:                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()    return Y</code></pre><p>torch.nn.MaxPool2d(kernel_size, stride&#x3D;None, padding&#x3D;0, dilation&#x3D;1, return_indices&#x3D;False, ceil_mode&#x3D;False)</p><pre><code class="Plain">kernel_size(int or tuple) ：max pooling的窗口大小stride(int or tuple, optional)：max pooling的窗口移动的步长。默认值是kernel_sizepadding(int or tuple, optional) ：输入的每一条边补充0的层数dilation(int or tuple, optional)：一个控制窗口中元素步幅的参数return_indices ：如果等于True，会返回输出最大值的序号，对于上采样操作会有帮助ceil_mode ：如果等于True，计算输出信号大小的时候，会使用向上取整，代替默认的向下取整的</code></pre><p>在处理多通道输入数据时，[<strong>汇聚层在每个输入通道上单独运算</strong>]，而不是像卷积层一样在通道上对输入进行汇总。 这意味着汇聚层的输出通道数与输入通道数相同。</p><h3 id="5-5、实战例子——LeNet"><a href="#5-5、实战例子——LeNet" class="headerlink" title="5.5、实战例子——LeNet"></a>5.5、实战例子——LeNet</h3><p><img src="https://raw.githubusercontent.com/LIyvqi/FigOfWeb/main/202206192138564.png" alt="img"></p><p>LeNet的组成部分有两个卷积层和三个全连接层实现，我们在这里直接学习一下如何调用现成的。</p><p>通过下面的LeNet代码，你会相信用深度学习框架实现此类模型非常简单。我们只需要实例化一个<code>Sequential</code>块并将需要的层连接在一起。</p><pre><code class="Python">import torchfrom torch import nnfrom d2l import torch as d2lnet = nn.Sequential(    nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(),    nn.AvgPool2d(kernel_size=2, stride=2),    nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),    nn.AvgPool2d(kernel_size=2, stride=2),    nn.Flatten(),    nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),    nn.Linear(120, 84), nn.Sigmoid(),    nn.Linear(84, 10))# 为了检查模型，打印每一层的形状X = torch.rand(size=(1, 1, 28, 28), dtype=torch.float32)for layer in net:    X = layer(X)  # 调用网络中的每一层，计算    print(layer.__class__.__name__,&#39;output shape: \t&#39;,X.shape)# 模型的训练batch_size = 256train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)def evaluate_accuracy_gpu(net, data_iter, device=None): #@save    &quot;&quot;&quot;使用GPU计算模型在数据集上的精度，这一部分其实从学习方法来讲不重要，无所谓&quot;&quot;&quot;    if isinstance(net, nn.Module):        net.eval()  # 设置为评估模式        if not device:            device = next(iter(net.parameters())).device    # 正确预测的数量，总预测的数量    metric = d2l.Accumulator(2)    with torch.no_grad():        for X, y in data_iter:            if isinstance(X, list):                # BERT微调所需的（之后将介绍）                X = [x.to(device) for x in X]            else:                X = X.to(device)            y = y.to(device)            metric.add(d2l.accuracy(net(X), y), y.numel())    return metric[0] / metric[1]# 模型的训练部分，也算是重点def train_ch6(net, train_iter, test_iter, num_epochs, lr, device):    &quot;&quot;&quot;用GPU训练模型(在第六章定义)&quot;&quot;&quot;    # 首先是初始化网络的参数    def init_weights(m):        if type(m) == nn.Linear or type(m) == nn.Conv2d:            nn.init.xavier_uniform_(m.weight)    net.apply(init_weights)        print(&#39;training on&#39;, device)    net.to(device)   # 把网络放入设备中        optimizer = torch.optim.SGD(net.parameters(), lr=lr)    loss = nn.CrossEntropyLoss()    # 指定优化器和损失函数        animator = d2l.Animator(xlabel=&#39;epoch&#39;, xlim=[1, num_epochs],                            legend=[&#39;train loss&#39;, &#39;train acc&#39;, &#39;test acc&#39;])    timer, num_batches = d2l.Timer(), len(train_iter)        for epoch in range(num_epochs):        # 训练损失之和，训练准确率之和，样本数        metric = d2l.Accumulator(3)        net.train()        for i, (X, y) in enumerate(train_iter):            timer.start()                        optimizer.zero_grad()            X, y = X.to(device), y.to(device)            y_hat = net(X)            l = loss(y_hat, y)            l.backward()            optimizer.step()                        with torch.no_grad():                metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])            timer.stop()            train_l = metric[0] / metric[2]            train_acc = metric[1] / metric[2]            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:                animator.add(epoch + (i + 1) / num_batches,                             (train_l, train_acc, None))        test_acc = evaluate_accuracy_gpu(net, test_iter)        animator.add(epoch + 1, (None, None, test_acc))    print(f&#39;loss &#123;train_l:.3f&#125;, train acc &#123;train_acc:.3f&#125;, &#39;          f&#39;test acc &#123;test_acc:.3f&#125;&#39;)    print(f&#39;&#123;metric[2] * num_epochs / timer.sum():.1f&#125; examples/sec &#39;          f&#39;on &#123;str(device)&#125;&#39;)  # 了解训练的基本过程就行，因为这个训练的代码集成了很多作者自己写的d2l的库，实际中不多# 主要是学习模型部分，代码的训练过程几乎开源的项目都有，找到自己适合的就行# 但是，一定要记住的是，在模型的训练中有很多坑，这个要整理好lr, num_epochs = 0.9, 10train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())</code></pre>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 卷积神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习花书(5)-深度模型计算</title>
      <link href="/2022/06/17/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%8A%B1%E4%B9%A6-5-%E6%B7%B1%E5%BA%A6%E6%A8%A1%E5%9E%8B%E8%AE%A1%E7%AE%97/"/>
      <url>/2022/06/17/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%8A%B1%E4%B9%A6-5-%E6%B7%B1%E5%BA%A6%E6%A8%A1%E5%9E%8B%E8%AE%A1%E7%AE%97/</url>
      
        <content type="html"><![CDATA[<p><a href="https://zh.d2l.ai/chapter_deep-learning-computation/index.html">https://zh.d2l.ai/chapter_deep-learning-computation/index.html</a>  </p><p>参考资料见上</p><h3 id="4-1、写在最前面，不熟悉的代码"><a href="#4-1、写在最前面，不熟悉的代码" class="headerlink" title="4.1、写在最前面，不熟悉的代码"></a>4.1、写在最前面，不熟悉的代码</h3><pre><code class="Python"># 一个自定义块的写法，等同于下面直接掉包class MLP(nn.Module):    # 用模型参数声明层。这里，我们声明两个全连接的层    def __init__(self):        # 调用MLP的父类Module的构造函数来执行必要的初始化。        # 这样，在类实例化时也可以指定其他函数参数，例如模型参数params（稍后将介绍）        super().__init__()        self.hidden = nn.Linear(20, 256)  # 隐藏层        self.out = nn.Linear(256, 10)  # 输出层            # 定义模型的前向传播，即如何根据输入X返回所需的模型输出    def forward(self, X):        # 注意，这里我们使用ReLU的函数版本，其在nn.functional模块中定义。        return self.out(F.relu(self.hidden(X)))# 当然也可以直接掉包from troch import nnnew_MLP = nn.Sequential(nn.Linear(20,256),nn.ReLU(),nn.Linear(256,10))net[][].state_dict() # 访问某一层网络的参数，按照数组的格式访问print(net[2].bias)   # tensor([0.1957], requires_grad=True)print(net[2].bias.data) # tensor([0.1957])net[2].weight.grad    # 访问梯度，在反向传播之前是负的梯度print(*[(name, param.shape) for name, param in net.named_parameters()]) # 一次性访问所有参数net.state_dict()[&#39;2.bias&#39;].data  按照字典访问参数# 参数的初始化方法def init_normal(m):    if type(m) == nn.Linear:  # 把所有的nn.Linear类型的层按照指定的分布初始化        nn.init.normal_(m.weight, mean=0, std=0.01)        # nn.init.constant_(m.weight, 1) 初始化为常数1        nn.init.zeros_(m.bias)net.apply(init_normal)   # 也可以net[0].apply(init_normal)，初始化某一层&quot;&quot;&quot;nn.Module里面关于参数有两个很重要的属性named_parameters()和parameters()，前者给出网络层的名字和参数的迭代器，而后者仅仅是参数的迭代器。&quot;&quot;&quot;# 层组成块，我们除了可以自定义块，还可以自定义层# 实现一个全连接层class MyLinear(nn.Module):    def __init__(self, inputs, units):        super().__init__()        self.weight = nn.Parameter(torch.randn(in_units, units))        self.bias = nn.Parameter(torch.randn(units,))    def forward(self, X):        linear = torch.matmul(X, self.weight.data) + self.bais.data        return F.relu(linear)# 读写文件，保存参数和模型torch.save(x, &#39;x-file&#39;)x2 = torch.load(&#39;x-file&#39;)torch.save(net.state_dict(), &#39;mlp.params&#39;)# 为了恢复模型，我们[实例化了原始多层感知机模型的一个备份。] # 这里我们不需要随机初始化模型参数，而是(直接读取文件中存储的参数。)clone = MLP()clone.load_state_dict(torch.load(&#39;mlp.params&#39;))   # 模型加载参数clone.eval()# 比较灵活，直接存就行，存的是什么格式，读出来就是什么格式module.train()   # 启用 Batch Normalization 和 Dropout。如果模型中有BN层(Batch Normalization）和Dropout，需要在训练时添加model.train()。module.eval()    # 不启用 Batch Normalization 和 Dropout。如果模型中有BN层(Batch Normalization）和Dropout，在测试时添加model.eval()device = torch.device(f&#39;cuda:&#123;i&#125;&#39;) X = torch.ones(2, 3, device=try_gpu())# 指定在哪一个GPU上创建# 将网络的模型指定在哪一个gpu上net = nn.Sequential(nn.Linear(3, 1))net = net.to(device=try_gpu())</code></pre><h3 id="4-2、块"><a href="#4-2、块" class="headerlink" title="4.2、块"></a>4.2、块</h3><p><em>块</em>（block）可以描述单个层、由多个层组成的组件或整个模型本身。 使用块进行抽象的一个好处是可以将一些块组合成更大的组件， 这一过程通常是递归的。</p><p><strong>深度神经网络的模型就是一个块一个块像搭积木一样搭起来的，很重要。</strong></p><p>如何自定义一个块，每个块必须提供以下基本功能：</p><ol><li><p>将输入数据作为其前向传播函数的参数。</p></li><li><p>通过前向传播函数来生成输出。请注意，输出的形状可能与输入的形状不同。例如第一个全连接的层接收一个20维的输入，但是返回一个维度为256的输出。</p></li><li><p>计算其输出关于输入的梯度，可通过其反向传播函数进行访问。通常这是自动发生的。</p></li><li><p>存储和访问前向传播计算所需的参数。</p></li><li><p>根据需要初始化模型参数。</p></li></ol><pre><code class="Python"># 一个块的标准定义class MLP(nn.Module):    # 用模型参数声明层。这里，我们声明两个全连接的层    def __init__(self):        # 调用MLP的父类Module的构造函数来执行必要的初始化。        # 这样，在类实例化时也可以指定其他函数参数，例如模型参数params（稍后将介绍）        super().__init__()        self.hidden = nn.Linear(20, 256)  # 隐藏层        self.out = nn.Linear(256, 10)  # 输出层    # 定义模型的前向传播，即如何根据输入X返回所需的模型输出    def forward(self, X):        # 注意，这里我们使用ReLU的函数版本，其在nn.functional模块中定义。        return self.out(F.relu(self.hidden(X)))# 当然也可以直接掉包from troch import nnnew_MLP = nn.Sequential(nn.Linear(20,256),nn.ReLU(),nn.Linear(256,10))</code></pre><p>上述的nn.Sequential()是一个顺序块，就是提前定义好的块，我们可以自己定义一下：</p><pre><code class="Python">class MySequential(nn.Module):    def __init__(self, *args):        super().__init__()        for idx, module in enumerate(args):            # 这里，module是Module子类的一个实例。我们把它保存在&#39;Module&#39;类的成员            # 变量_modules中。module的类型是OrderedDict            self._modules[str(idx)] = module        def forward(self,X):        # OrderedDict 保证了成员变量添加的属性遍历他们        for block in self._modules.values():            X = block(X)        return X</code></pre><p>对于一个块来说，是你可以随心所欲设计的，想怎么组合怎么混合都可以。</p><h3 id="4-3、模型中参数的管理：访问、初始化、共享"><a href="#4-3、模型中参数的管理：访问、初始化、共享" class="headerlink" title="4.3、模型中参数的管理：访问、初始化、共享"></a>4.3、模型中参数的管理：访问、初始化、共享</h3><p>从已有模型中访问参数。 当通过<code>Sequential</code>类定义模型时， 我们可以通过索引来访问模型的任意层。 这就像模型是一个列表一样，每层的参数都在其属性中。 如下所示，我们可以检查第二个全连接层的参数。 注意，参数名称允许唯一标识每个参数，即使在包含数百个层的网络中也是如此。</p><pre><code class="Python">net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))print(net[2].state_dict())  # 这就是访问的 nn.Linear(8, 1)的参数# OrderedDict([(&#39;weight&#39;, tensor([[-0.1976,  0.2988,  0.0623, -0.2936, -0.2918, -0.2031,  0.1552,  0.0943]])), # (&#39;bias&#39;, tensor([0.1957]))])</code></pre><p>访问目标参数，比如访问第三个神经网络层（nn.Linear(8,1)）的偏置。</p><pre><code class="Python">print(net[2].bias)   # tensor([0.1957], requires_grad=True)print(net[2].bias.data) # tensor([0.1957])net[2].weight.grad    # 访问梯度，在反向传播之前是负的梯度print(*[(name, param.shape) for name, param in net.named_parameters()]) # 一次性访问所有参数net.state_dict()[&#39;2.bias&#39;].data  按照字典访问参数</code></pre><p>深度神经网络的网络层是分层嵌套的，所以我们也可以像通过嵌套列表索引一样访问它们。</p><p>可以直接print(net)查看，索引是从0开始，可以按照net[][]的格式访问。</p><p><strong>参数的初始化：</strong></p><pre><code class="Python"># 方法一def init_normal(m):    if type(m) == nn.Linear:  # 把所有的nn.Linear类型的层按照指定的分布初始化        nn.init.normal_(m.weight, mean=0, std=0.01)        # nn.init.constant_(m.weight, 1) 初始化为常数1        nn.init.zeros_(m.bias)net.apply(init_normal)# 方法二def xavier(m):    if type(m) == nn.Linear:        nn.init.xavier_uniform_(m.weight)def init_42(m):    if type(m) == nn.Linear:        nn.init.constant_(m.weight, 42)net[0].apply(xavier)   # 指定这一个层使用xavier初始化方法，如果没有[0]指定的话是针对所有的层net[2].apply(init_42)# 方法三 自定义的参数更新，其实无论怎么样，我们只要自定义一个参数更新的方式# 然后 nn.apply(my_init)def my_init(m):    if type(m) == nn.Linear:        # print(&quot;Init&quot;, *[(name, param.shape)        #                 for name, param in m.named_parameters()][0])        nn.init.uniform_(m.weight, -10, 10)        m.weight.data *= m.weight.data.abs() &gt;= 5net.apply(my_init)</code></pre><p>nn.Module里面关于参数有两个很重要的属性named_parameters()和parameters()，前者给出<strong>网络层的名字和参数</strong>的迭代器，而后者<strong>仅仅是参数</strong>的迭代器。</p><p>参数绑定（参数共享）</p><p>有时我们希望在多个层间共享参数： 我们可以定义一个稠密层，然后使用它的参数来设置另一个层的参数。</p><pre><code class="Python"># 我们需要给共享层一个名称，以便可以引用它的参数shared = nn.Linear(8, 8)net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(),                    shared,                    nn.ReLU(),                    shared,                    nn.ReLU(),                    nn.Linear(8, 1))net(X)</code></pre><p>这个例子表明第三个和第五个神经网络层的参数是绑定的。 它们不仅值相等，而且由相同的张量表示。 因此，如果我们改变其中一个参数，另一个参数也会改变。 你可能会思考：当参数绑定时，梯度会发生什么情况？ <strong>答案是由于模型参数包含梯度，因此在反向传播期间第二个隐藏层 （即第三个神经网络层）和第三个隐藏层（即第五个神经网络层）的梯度会加在一起</strong>。</p><h3 id="4-4、自定义层"><a href="#4-4、自定义层" class="headerlink" title="4.4、自定义层"></a>4.4、自定义层</h3><p>深度学习成功背后的一个因素是神经网络的灵活性： 我们可以用创造性的方式组合不同的层，从而设计出适用于各种任务的架构。</p><p> 我们可以使用内置函数来创建参数，这些函数提供一些基本的管理功能。 比如管理访问、初始化、共享、保存和加载模型参数。 这样做的好处之一是：我们不需要为每个自定义层编写自定义的序列化程序。</p><pre><code class="Python"># 实现一个全连接层class MyLinear(nn.Module):    def __init__(self, inputs, units):        super().__init__()        self.weight = nn.Parameter(torch.randn(in_units, units))        self.bias = nn.Parameter(torch.randn(units,))    def forward(self, X):        linear = torch.matmul(X, self.weight.data) + self.bais.data        return F.relu(linear)        net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))net(torch.rand(2, 64))</code></pre><h3 id="4-5、读写文件"><a href="#4-5、读写文件" class="headerlink" title="4.5、读写文件"></a>4.5、读写文件</h3><p>加载和保存张量   torch.save()   torch.load()</p><pre><code class="Python">x = torch.arange(4)torch.save(x, &#39;x-file&#39;)x2 = torch.load(&#39;x-file&#39;)y = torch.zeros(4)torch.save([x, y],&#39;x-files&#39;)mydict = &#123;&#39;x&#39;: x, &#39;y&#39;: y&#125;torch.save(mydict, &#39;mydict&#39;)# 比较灵活，直接存就行，存的是什么格式，读出来就是什么格式</code></pre><p>保存整个模型，其实保存的就是这个模型的参数。</p><pre><code class="Python">torch.save(net.state_dict(), &#39;mlp.params&#39;)# 为了恢复模型，我们[实例化了原始多层感知机模型的一个备份。] # 这里我们不需要随机初始化模型参数，而是(直接读取文件中存储的参数。)clone = MLP()clone.load_state_dict(torch.load(&#39;mlp.params&#39;))   # 模型加载参数clone.eval()</code></pre><p>**model.train()**的作用是启用 Batch Normalization <strong>和</strong> Dropout。如果模型中有BN层(Batch Normalization）和Dropout，需要在训练时添加model.train()。model.train()是保证BN层能够用到每一批数据的均值和方差。对于Dropout，model.train()是随机取一部分网络连接来训练更新参数。</p><p>**model.eval()**的作用是不启用 Batch Normalization <strong>和</strong> Dropout。如果模型中有BN层(Batch Normalization）和Dropout，在测试时添加model.eval()。model.eval()是保证BN层能够用全部训练数据的均值和方差，即测试过程中要保证BN层的均值和方差不变。对于Dropout，model.eval()是利用到了所有网络连接，即不进行随机舍弃神经元。训练完train样本后，生成的模型model要用来测试样本。在model(test)之前，需要加上model.eval()，否则的话，有输入数据，即使不训练，它也会改变权值。这是model中含有BN层和Dropout所带来的的性质。在做one classification的时候，训练集和测试集的样本分布是不一样的，尤其需要注意这一点。</p><h3 id="4-6、GPU的调用"><a href="#4-6、GPU的调用" class="headerlink" title="4.6、GPU的调用"></a>4.6、GPU的调用</h3><pre><code class="Python">def try_gpu(i=0):  #@save    &quot;&quot;&quot;如果存在，则返回gpu(i)，否则返回cpu()&quot;&quot;&quot;    if torch.cuda.device_count() &gt;= i + 1:        return torch.device(f&#39;cuda:&#123;i&#125;&#39;)    return torch.device(&#39;cpu&#39;)def try_all_gpus():  #@save    &quot;&quot;&quot;返回所有可用的GPU，如果没有GPU，则返回[cpu(),]&quot;&quot;&quot;    devices = [torch.device(f&#39;cuda:&#123;i&#125;&#39;)             for i in range(torch.cuda.device_count())]    return devices if devices else [torch.device(&#39;cpu&#39;)]</code></pre><p>默认情况下，张量是在CPU上创建的，无论何时我们要对多个项进行操作， <strong>它们都必须在同一个设备上，且区分GPU1和GPU2。</strong> 例如，如果我们对两个张量求和， 我们需要确保两个张量都位于同一个设备上， 否则框架将不知道在哪里存储结果，甚至不知道在哪里执行计算。</p><pre><code class="Python">X = torch.ones(2, 3, device=try_gpu())# 指定在哪一个GPU上创建# 将网络的模型指定在哪一个gpu上net = nn.Sequential(nn.Linear(3, 1))net = net.to(device=try_gpu())</code></pre><p>不经意地移动数据可能会显著降低性能。<strong>一个典型的错误如下</strong>：计算GPU上每个小批量的损失，并在命令行中将其报告给用户（或将其记录在NumPy <code>ndarray</code>中）时，将触发全局解释器锁，从而使所有GPU阻塞。最好是为GPU内部的日志分配内存，并且只移动较大的日志。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 块 </tag>
            
            <tag> 参数控制 </tag>
            
            <tag> 自定义层 </tag>
            
            <tag> 读写模型 </tag>
            
            <tag> GPU调用 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习花书（4）-多层感知机下</title>
      <link href="/2022/06/16/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%8A%B1%E4%B9%A6%EF%BC%884%EF%BC%89-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E4%B8%8B/"/>
      <url>/2022/06/16/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%8A%B1%E4%B9%A6%EF%BC%884%EF%BC%89-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E4%B8%8B/</url>
      
        <content type="html"><![CDATA[<p><a href="https://zh.d2l.ai/chapter_multilayer-perceptrons/kaggle-house-price.html">https://zh.d2l.ai/chapter_multilayer-perceptrons/kaggle-house-price.html</a></p><p>这是天池竞赛的放假预测的实例，一个广泛的用于练手的项目，数据集处理占了大头😂，参考的链接见上，下面是详细的代码。</p><pre><code class="python">import hashlibimport osimport tarfileimport zipfileimport requests#@saveDATA_HUB = dict()DATA_URL = &#39;http://d2l-data.s3-accelerate.amazonaws.com/&#39;def download(name, cache_dir = os.path.join(&#39;..&#39;, &#39;data&#39;)):    &quot;&quot;&quot;下载一个DATA_HUB中的文件，返回本地文件名&quot;&quot;&quot;    assert name in DATA_HUB, f&quot;&#123;name&#125; 不存在于 &#123;DATA_HUB&#125;&quot;    url, sha1_hash = DATA_HUB[name]    os.makedirs(cache_dir, exist_ok=True)    fname = os.path.join(cache_dir, url.split(&#39;/&#39;)[-1])    if os.path.exists(fname):        sha1 = hashlib.sha1()        with open(fname, &#39;rb&#39;) as f:            while True:                data = f.read(1048576)                if not data:                    break                sha1.update(data)        if sha1.hexdigest() == sha1_hash:            return fname  # 命中缓存    print(f&#39;正在从&#123;url&#125;下载&#123;fname&#125;...&#39;)    r = requests.get(url, stream=True, verify=True)    with open(fname, &#39;wb&#39;) as f:        f.write(r.content)    return fname# 下面还有实现两个函数，一个将下载并解压缩一个zip或tar文件，# 另一个是将本书中使用的所有数据集从DATA_HUB下载到缓存目录中。def download_extract(name, folder=None):  #@save    &quot;&quot;&quot;下载并解压zip/tar文件&quot;&quot;&quot;    fname = download(name)    base_dir = os.path.dirname(fname)    data_dir, ext = os.path.splitext(fname)    if ext == &#39;.zip&#39;:        fp = zipfile.ZipFile(fname, &#39;r&#39;)    elif ext in (&#39;.tar&#39;, &#39;.gz&#39;):        fp = tarfile.open(fname, &#39;r&#39;)    else:        assert False, &#39;只有zip/tar文件可以被解压缩&#39;    fp.extractall(base_dir)    return os.path.join(base_dir, folder) if folder else data_dirdef download_all():  #@save    &quot;&quot;&quot;下载DATA_HUB中的所有文件&quot;&quot;&quot;    for name in DATA_HUB:        download(name)%matplotlib inlineimport numpy as npimport pandas as pdimport torchfrom torch import nnfrom d2l import torch as d2l# 下载并缓存数据集DATA_HUB[&#39;kaggle_house_train&#39;] = (  #@save    DATA_URL + &#39;kaggle_house_pred_train.csv&#39;,    &#39;585e9cc93e70b39160e7921475f9bcd7d31219ce&#39;)DATA_HUB[&#39;kaggle_house_test&#39;] = (  #@save    DATA_URL + &#39;kaggle_house_pred_test.csv&#39;,    &#39;fa19780a7b011d9b009e8bff8e99922a8ee2eb90&#39;)train_data = pd.read_csv(download(&#39;kaggle_house_train&#39;))test_data = pd.read_csv(download(&#39;kaggle_house_test&#39;))# 上述是完成了数据的加载，核心的模型部分是下面# (在每个样本中，第一个特征是ID，) 这有助于模型识别每个训练样本。 虽然这很方便，但它不携带任何用于预测的信息。 因此，# 在将数据提供给模型之前，(我们将其从数据集中删除)。all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:]))# 若无法获得测试数据，则可根据训练数据计算均值和标准差numeric_features = all_features.dtypes[all_features.dtypes != &#39;object&#39;].indexall_features[numeric_features] = all_features[numeric_features].apply(    lambda x: (x - x.mean()) / (x.std()))# 在标准化数据之后，所有均值消失，因此我们可以将缺失值设置为0all_features[numeric_features] = all_features[numeric_features].fillna(0)# “Dummy_na=True”将“na”（缺失值）视为有效的特征值，并为其创建指示符特征all_features = pd.get_dummies(all_features, dummy_na=True)  # 离散值使用独热编码all_features.shape</code></pre>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 多层感知机 </tag>
            
            <tag> 房价预测 </tag>
            
            <tag> kaggle实例 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习花书(3)-多层感知机上</title>
      <link href="/2022/06/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%8A%B1%E4%B9%A6-3-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E4%B8%8A/"/>
      <url>/2022/06/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%8A%B1%E4%B9%A6-3-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E4%B8%8A/</url>
      
        <content type="html"><![CDATA[<p>多层感知机算是深度神经网络的入门开始，参考资料：<a href="https://zh.d2l.ai/chapter_multilayer-perceptrons/index.html">https://zh.d2l.ai/chapter_multilayer-perceptrons/index.html</a></p><h3 id="0、不熟悉的一些核心代码"><a href="#0、不熟悉的一些核心代码" class="headerlink" title="0、不熟悉的一些核心代码"></a>0、不熟悉的一些核心代码</h3><pre><code class="python"># 清除以前的梯度,代码x.grad.data.zero_()# 设置为可训练的可求导的参数W1 = nn.Parameter(torch.randn(num_inputs, num_hiddens, requires_grad=True) * 0.01)# 通过API实现多层感知机，这算是最简单的深度学习了吧# 导入包import torchfrom torch import nnfrom d2l import torch as d2l# 模型net = nn.Sequential(nn.Flatten(),                    nn.Linear(784, 256),                    nn.ReLU(),                    nn.Linear(256, 10))# 初始化参数                    def init_weights(m):    if type(m) == nn.Linear:        nn.init.normal_(m.weight, std=0.01)net.apply(init_weights)batch_size, lr, num_epochs = 256, 0.1, 10loss = nn.CrossEntropyLoss(reduction=&#39;none&#39;)trainer = torch.optim.SGD(net.parameters(), lr=lr)train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)# 为了在取对数时进一步稳定该值，将小于1的值设置为1# torch.clamp()就是把数值的区间限制在给定的区间之间clipped_preds = torch.clamp(net(features), 1, float(&#39;inf&#39;))# pandas处理数据的一段代码# 若无法获得测试数据，则可根据训练数据计算均值和标准差numeric_features = all_features.dtypes[all_features.dtypes != &#39;object&#39;].indexall_features[numeric_features] = all_features[numeric_features].apply(    lambda x: (x - x.mean()) / (x.std()))# 在标准化数据之后，所有均值消失，因此我们可以将缺失值设置为0all_features[numeric_features] = all_features[numeric_features].fillna(0)</code></pre><p><code>DataFrame</code> 有一个方便的 <code>dtypes</code> 属性用于返回一个包含每个列的数据类型的序列，</p><p><em>训练误差</em>（training error）是指， 模型在训练数据集上计算得到的误差。 <em>泛化误差</em>（generalization error）是指， 模型应用在同样从原始样本的分布中抽取的无限多数据样本时，模型误差的期望。</p><h2 id="1、K折交叉验证"><a href="#1、K折交叉验证" class="headerlink" title="1、K折交叉验证"></a>1、K折交叉验证</h2><p>​当训练数据稀缺时，我们甚至可能无法提供足够的数据来构成一个合适的验证集。 这个问题的一个流行的解决方案是采用<strong>𝐾</strong><em><strong>折交叉验证</strong></em>。 这里，原始训练数据被分成𝐾个不重叠的子集。 然后执行K次模型训练和验证，每次在𝐾−1个子集上进行训练， 并在剩余的一个子集（在该轮中没有用于训练的子集）上进行验证。 最后，<strong>通过对𝐾次实验的结果取平均来估计训练和验证误差</strong>。</p><h2 id="2、过拟合和欠拟合"><a href="#2、过拟合和欠拟合" class="headerlink" title="2、过拟合和欠拟合"></a>2、过拟合和欠拟合</h2><p>判断：</p><p>1、训练误差和验证误差都很严重， 但它们之间仅有一点差距。 如果模型不能降低训练误差，这可能意味着模型过于简单，欠拟合。</p><p>2、训练误差明显低于验证误差时要小心， 这表明严重的<em>过拟合</em>（overfitting），但是最好的预测模型在训练数据上的表现往往比在保留（验证）数据上好得多。 最终，我们通常更关心验证误差。</p><p>解决过拟合的方法：</p><p>1、限制特征的数量（例如拟合时调整阶数）</p><p>2、参数的权重衰减（范数）。使用L2范数的一个原因是它对权重向量的大分量施加了巨大的惩罚。 这使得我们的学习算法偏向于在大量特征上均匀分布权重的模型。 在实践中，这可能使它们对单个变量中的观测误差更为稳定。 相比之下，L1惩罚会导致模型将权重集中在一小部分特征上， 而将其他权重清除为零。 这称为<em>特征选择</em>（feature selection），这可能是其他场景下需要的。</p><p>pytorch中集成了权重衰减的代码</p><p>在实例化优化器时直接通过<code>weight_decay</code>指定weight decay超参数。 默认情况下，PyTorch同时衰减权重和偏移。 这里我们只为权重设置了<code>weight_decay</code>，所以偏置参数𝑏不会衰减。</p><pre><code class="Plain">net = nn.Sequential(nn.Linear(num_inputs, 1))for param in net.parameters():    param.data.normal_()loss = nn.MSELoss(reduction=&#39;none&#39;)num_epochs, lr = 100, 0.003# 偏置参数没有衰减trainer = torch.optim.SGD([    &#123;&quot;params&quot;:net[0].weight,&#39;weight_decay&#39;: wd&#125;,    &#123;&quot;params&quot;:net[0].bias&#125;], lr=lr)</code></pre><h2 id="3、Dropout"><a href="#3、Dropout" class="headerlink" title="3、Dropout"></a>3、Dropout</h2><pre><code class="Python">实现dropout的两行核心代码，X是输入的特征mask = (torch.rand(X.shape) &gt; dropout).float()  # 直接在每一个位置都转为了0或1return mask * X / (1.0 - dropout)在torch中是有集成的torch.nn.Dropout(0.3)</code></pre><h2 id="4、梯度消失和梯度爆炸"><a href="#4、梯度消失和梯度爆炸" class="headerlink" title="4、梯度消失和梯度爆炸"></a>4、梯度消失和梯度爆炸</h2><p>​不稳定梯度带来的风险不止在于数值表示； 不稳定梯度也威胁到我们优化算法的稳定性。 我们可能面临一些问题。 要么是<em>梯度爆炸</em>（gradient exploding）问题： 参数更新过大，破坏了模型的稳定收敛； 要么是<em>梯度消失</em>（gradient vanishing）问题： 参数更新过小，在每次更新时几乎不会移动，导致模型无法学习。</p><p>Sigmoid激活函数经常会遇到梯度消失的问题，如下，所以现在默认选择 relu激活函数</p><img src="https://raw.githubusercontent.com/LIyvqi/FigOfWeb/main/202206152248418.png" alt="img" style="zoom:50%;" /><ul><li><p><strong>在模型的训练和设计中要打破对称性</strong>，在前向传播期间，两个隐藏单元采用相同的输入和参数， 产生相同的激活，该激活被送到输出单元。 在反向传播期间，根据参数𝐖(1)对输出单元进行微分， 得到一个梯度，其元素都取相同的值。 因此，在基于梯度的迭代（例如，小批量随机梯度下降）之后， 𝐖(1)的所有元素仍然采用相同的值。 这样的迭代永远不会打破对称性，我们可能永远也无法实现网络的表达能力。虽然小批量随机梯度下降不会打破这种对称性，但暂退法正则化可以。</p></li><li><ul><li>解决上述问题最重要的途径就是参数初始化：</li></ul></li></ul><p>默认初始化：不指定初始化方法， 框架将使用默认的随机初始化方法，对于中等难度的问题，这种方法通常很有效。</p><p>Xavier初始化是在“不存在非线性”的假设中推导出来的，但是实践中的效果非常好。对于每一层，输出的方差不受输入数量的影响，任何梯度的方差不受输出数量的影响。</p><p><img src="https://raw.githubusercontent.com/LIyvqi/FigOfWeb/main/202206152248441.png" alt="img"></p><p>python中assert的使用： </p><pre><code class="Python">import sysassert (&#39;linux&#39; in sys.platform), &quot;该代码只能在 Linux 下执行&quot;# 如果assert后面的为True，下面的代码正常执行，如果不是，触发异常并抛出# 接下来要执行的代码</code></pre>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 多层感知机 </tag>
            
            <tag> 过（欠）拟合 </tag>
            
            <tag> 梯度消失和爆炸 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习花书(2)-逻辑回归</title>
      <link href="/2022/06/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%8A%B1%E4%B9%A6-2-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
      <url>/2022/06/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%8A%B1%E4%B9%A6-2-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/</url>
      
        <content type="html"><![CDATA[<p><a href="https://zh.d2l.ai/chapter_linear-networks/index.html">https://zh.d2l.ai/chapter_linear-networks/index.html</a></p><p>参考资料如上</p><pre><code class="Plain">def sgd(params, lr, batch_size):  #@save  sgd的具体实现    &quot;&quot;&quot;小批量随机梯度下降&quot;&quot;&quot;    # torch.no_grad() 是一个上下文管理器，被该语句 wrap 起来的部分将不会track 梯度    with torch.no_grad():          for param in params:            param -= lr * param.grad / batch_size            param.grad.zero_()# 实际训练的过程for epoch in range(num_epochs):    for X, y in data_iter(batch_size, features, labels):        l = loss(net(X, w, b), y)  # X和y的小批量损失        # 因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起，        # 并以此计算关于[w,b]的梯度        l.sum().backward()        sgd([w, b], lr, batch_size)  # 使用参数的梯度更新参数# 上述是手动实现的核心代码，如果通过torch实现非常简单import numpy as npimport torchfrom torch.utils import datafrom d2l import torch as d2ltrue_w = torch.tensor([2, -3.4])true_b = 4.2features, labels = d2l.synthetic_data(true_w, true_b, 1000)def load_array(data_arrays, batch_size, is_train=True):  #@save    &quot;&quot;&quot;构造一个PyTorch数据迭代器&quot;&quot;&quot;    dataset = data.TensorDataset(*data_arrays)    return data.DataLoader(dataset, batch_size, shuffle=is_train)batch_size = 10data_iter = load_array((features, labels), batch_size)# nn是神经网络的缩写from torch import nnnet = nn.Sequential(nn.Linear(2, 1))# 我们通过`net[0]`选择网络中的第一个图层，然后使用`weight.data`和`bias.data`方法访问参数。# 我们还可以使用替换方法`normal_`和`fill_`来重写参数值。net[0].weight.data.normal_(0, 0.01),net[0].bias.data.fill_(0)loss = nn.MSELoss() # 定义损失函数trainer = torch.optim.SGD(net.parameters(), lr=0.03)# 训练num_epochs = 3for epoch in range(num_epochs):    for X, y in data_iter:        l = loss(net(X) ,y)        trainer.zero_grad()        l.backward()        trainer.step()    l = loss(net(features), labels)    print(f&#39;epoch &#123;epoch + 1&#125;, loss &#123;l:f&#125;&#39;)w = net[0].weight.dataprint(&#39;w的估计误差：&#39;, true_w - w.reshape(true_w.shape))b = net[0].bias.dataprint(&#39;b的估计误差：&#39;, true_b - b)</code></pre><p>逻辑回归，图像分类</p><pre><code class="Python">def get_dataloader_workers():  #@save    &quot;&quot;&quot;使用4个进程来读取数据&quot;&quot;&quot;    return 4train_iter = data.DataLoader(mnist_train, batch_size, shuffle=True,                             num_workers=get_dataloader_workers())# 准确率指标的计算def accuracy(y_hat, y):  #@save    &quot;&quot;&quot;计算预测正确的数量&quot;&quot;&quot;    if len(y_hat.shape) &gt; 1 and y_hat.shape[1] &gt; 1:        y_hat = y_hat.argmax(axis=1)    cmp = y_hat.type(y.dtype) == y    return float(cmp.type(y.dtype).sum())# 交叉熵的实现def cross_entropy(y_hat, y):    return - torch.log(y_hat[range(len(y_hat)), y])  </code></pre><p>softmax回归的简洁版本实现</p><pre><code class="Python">import torchfrom torch import nnfrom d2l import torch as d2lbatch_size = 256train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)# PyTorch不会隐式地调整输入的形状。因此，# 我们在线性层前定义了展平层（flatten），来调整网络输入的形状net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10))def init_weights(m):    if type(m) == nn.Linear:        nn.init.normal_(m.weight, std=0.01)net.apply(init_weights);loss = nn.CrossEntropyLoss(reduction=&#39;none&#39;)trainer = torch.optim.SGD(net.parameters(), lr=0.1)num_epochs = 10d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)</code></pre><p>pytorch的任何网络<code>net</code>，都是<code>torch.nn.Module</code>的子类,都算是<code>module</code>，也就是模块。pytorch中的<code>model.apply(fn)</code>会递归地将函数<code>fn</code>应用到父模块的每个子模块<code>submodule</code>，也包括<code>model</code>这个父模块自身。</p><p>对于net.apply()，将一个函数fn递归地应用到模块自身以及该模块的每一个子模块(即在函数.children()中返回的子模块).该方法通常用来初始化一个模型中的参数(另见torch-nn-init部分的内容).</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 逻辑回归 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2022年老婆生日快乐</title>
      <link href="/2022/06/13/2022%E5%B9%B4%E8%80%81%E5%A9%86%E7%94%9F%E6%97%A5%E5%BF%AB%E4%B9%90/"/>
      <url>/2022/06/13/2022%E5%B9%B4%E8%80%81%E5%A9%86%E7%94%9F%E6%97%A5%E5%BF%AB%E4%B9%90/</url>
      
        <content type="html"><![CDATA[<h2 id="祝我亲爱的老婆生日快乐"><a href="#祝我亲爱的老婆生日快乐" class="headerlink" title="祝我亲爱的老婆生日快乐"></a>祝我亲爱的老婆生日快乐</h2><p>你是我遥望的一颗星星</p><p>繁星暗淡 只望见你</p><p>不知所以 更想你</p><p>想留住你 想拥抱你</p><p>擦亮银河 照亮你</p><pre><code>等我去找你哦，一起过一个快快乐乐的生日！</code></pre><p>  <img src="https://raw.githubusercontent.com/LIyvqi/FigOfWeb/main/202206132215420.png" alt="我最美"> </p> <img src="https://raw.githubusercontent.com/LIyvqi/FigOfWeb/main/202206132215199.png" alt="我最可爱" style="zoom: 80%;" /><p> <img src="https://raw.githubusercontent.com/LIyvqi/FigOfWeb/main/202206132216651.png" alt="一直幸福哦"> </p>]]></content>
      
      
      <categories>
          
          <category> Love </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 老婆生日 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习花书-预备知识</title>
      <link href="/2022/06/13/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%8A%B1%E4%B9%A6Day1-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/"/>
      <url>/2022/06/13/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%8A%B1%E4%B9%A6Day1-%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86/</url>
      
        <content type="html"><![CDATA[<h2 id="0、写在最前面"><a href="#0、写在最前面" class="headerlink" title="0、写在最前面"></a>0、写在最前面</h2><p>​计划重新学习一下深度学习这本书的内容，我选择的是李沐老师翻译的部分，开源在网站中，可以见文末，计划一个月内学完，并且把不熟悉的部分整理一下，因为之前也是有些基础的，此教程是我在闲暇时间查漏补缺的内容，个人主观性较强，但是学习路线很明确，欢迎大家一起学习~</p><h2 id="1、pandas"><a href="#1、pandas" class="headerlink" title="1、pandas"></a>1、pandas</h2><pre><code class="Python"># pandas按照位置读取和缺失值的处理# data.iloc[]  中括号， fillna 缺失值的填充inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]inputs = inputs.fillna(inputs.mean())inputs = pd.get_dummies(inputs, dummy_na=True)    # get_dummies是自动将文字型转化为数值型x.shape    # 没有括号，张量的形状A = torch.arange(20, dtype=torch.float32).reshape(5, 4)B = A.clone()  # 通过分配新内存，将A的一个副本分配给B2+A   #将张量乘以或加上一个标量不会改变张量的形状，其中张量的每个元素都将与标量相加或相乘# 在tensor中，是面向对象来进行最大最小值的求解的A.sum()sum_A = A.sum(axis=1, keepdims=True) #在调用函数来[计算总和或均值时保持轴数不变]会很有用# axis=0的时候一般是沿着向下的方法，axis=1的时候沿着横轴的方法# 矩阵的向量积A.shape, x.shape, torch.mv(A, x) # (torch.Size([5, 4]), torch.Size([4]), tensor([ 12.,  44.,  76., 108., 140.]))# 矩阵的乘法torch.mm(A, B)# torch求二范数和一范数torch.norm(u),torch.abs(u).sum()</code></pre><h2 id="微积分"><a href="#微积分" class="headerlink" title="微积分"></a>微积分</h2><pre><code class="Python"># 自动求导求梯度的例子import torchx = torch.arange(4.0)x.requires_grad_(True)# 等价于x=torch.arange(4.0,requires_grad=True)x.grad  # 默认值是Noney = 2 * torch.dot(x, x)y.backward()x.grad    # tensor([ 0.,  4.,  8., 12.])   x.grad == 4 * x   # tensor([True, True, True, True])# 在默认情况下，PyTorch会累积梯度，我们需要清除之前的值x.grad.zero_()y = x.sum()y.backward()x.gradx.grad_zero() #tensor([0., 1., 2., 3.], requires_grad=True)  清理了梯度，回到之前</code></pre><h2 id="概率及采样"><a href="#概率及采样" class="headerlink" title="概率及采样"></a>概率及采样</h2><pre><code class="Python">from torch.distributions import multinomialfair_probs = torch.ones([6]) / 6# 将结果存储为32位浮点数以进行除法counts = multinomial.Multinomial(1000, fair_probs).sample() #它在索引𝑖i处的值是采样结果中𝑖i出现的次数counts / 1000  # 相对频率作为估计值# 上述就是按照fair_probs的概率模拟抽样import torchprint(dir(torch.distributions))# 查看torch中distributions里面内置的函数help(torch.ones)    # 查看具体的用法</code></pre><h2 id="笔记出处—完整教程"><a href="#笔记出处—完整教程" class="headerlink" title="笔记出处—完整教程"></a>笔记出处—完整教程</h2><p><a href="https://zh.d2l.ai/chapter_preliminaries/index.html">https://zh.d2l.ai/chapter_preliminaries/index.html</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 预备知识 </tag>
            
            <tag> 微积分 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo写博客中会遇到的问题（持续更新）</title>
      <link href="/2022/06/12/Hexo%E5%86%99%E5%8D%9A%E5%AE%A2%E4%B8%AD%E4%BC%9A%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%88%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0%EF%BC%89/"/>
      <url>/2022/06/12/Hexo%E5%86%99%E5%8D%9A%E5%AE%A2%E4%B8%AD%E4%BC%9A%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%88%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h2 id="1、白嫖飞书的图床"><a href="#1、白嫖飞书的图床" class="headerlink" title="1、白嫖飞书的图床"></a>1、白嫖飞书的图床</h2><p>​因为学校一直用飞书，之前经常在飞书云文档记笔记，我发现在飞书云文档上传照片的时候，直接复制到.md文件中复制过来的居然是图床的链接，那这样只要飞书的文件不删除，就可以一直白嫖了，哈哈哈哈。</p><p>​过了一天之后发现飞书得到图床居然是动态更新的，第二天就用不了了，无语啊。后来我又改成了Github的仓库做图床。</p><p>​下载PicGo软件，找到图床设置，选择Github的图床就行。</p><img src="https://raw.githubusercontent.com/LIyvqi/FigOfWeb/main/image-20220612233642481.png" alt="image-20220612233642481" style="zoom:50%;" /><img src="https://raw.githubusercontent.com/LIyvqi/FigOfWeb/main/image-20220612233822432.png" alt="image-20220612233822432" style="zoom: 25%;" /><p>在typora的偏好设置中也选择，这样以后直接复制到typora中的照片就可以，不用管别的了。</p><p>​但是考虑到GitHub的存储空间是有限的，只有1个G，之后就没了，后来发现了 又拍云 这个网站，就在我的首页有跳转链接，直接百度搜索就行，比较容易。</p><p>​又拍云有一个活动，每年免费送一次空间和流量，只需要在网站的主页上放上他的广告即可。</p><p><a href="https://www.upyun.com/league">https://www.upyun.com/league</a>     进入此网站，按照教程申请即可。</p><img src="http://liyuqi-image.test.upcdn.net/202206131927395.png" alt="image-20220613192711265" style="zoom:25%;" /> <h2 id="2、报错问题-SSH连接的443"><a href="#2、报错问题-SSH连接的443" class="headerlink" title="2、报错问题 SSH连接的443"></a>2、报错问题 SSH连接的443</h2><p>​写好了博客上传的时候总是会出现连接超时 port 443： Timed out和OpenSSL错误的问题，教程的很多方法都不太好，直接改掉根目录配置文件_config.yml的deploy这部分。</p><pre><code>deploy:  type: git  repository: git@github.com:YOURNAME.github.io.git # 把https的协议换成git的，可以去仓库看  branch: main</code></pre>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 写作 </tag>
            
            <tag> 问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo-GitHub配置个人网站</title>
      <link href="/2022/06/12/Hexo-GitHub%E9%85%8D%E7%BD%AE%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/"/>
      <url>/2022/06/12/Hexo-GitHub%E9%85%8D%E7%BD%AE%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/</url>
      
        <content type="html"><![CDATA[<p>参考：<a href="https://www.bilibili.com/video/BV1mU4y1j72n?spm_id_from=333.999.0.0">【2021最新版】保姆级Hexo+github搭建个人博客_哔哩哔哩_bilibili</a></p><p>比着视频来一遍，非常简单，视频大约30min，实操1小时就ok，整个教程都非常顺利，没有任何bug。</p><h2 id="1、工具的安装"><a href="#1、工具的安装" class="headerlink" title="1、工具的安装"></a>1、工具的安装</h2><p>需要安装 <a href="https://www.cnblogs.com/zhouyu2017/p/6485265.html">Node.js安装及环境配置之Windows篇 - 周瑜周 - 博客园</a>，把这些工具都安装成果之后查看是否ok。</p><p>node -v</p><p>npm -v</p><p>git –version</p><p>hexo -v</p><h2 id="2、创建自己的Github仓库"><a href="#2、创建自己的Github仓库" class="headerlink" title="2、创建自己的Github仓库"></a>2、创建自己的Github仓库</h2><p>在创建仓库的时候，一定要把仓库命名为<a href="https://github.com/LIyvqi/LIyvqi.github.io">LIyvqi.github.i</a>o  LIyvqi是我的github用户名。</p><h2 id="3、生成SSH的密钥并绑定"><a href="#3、生成SSH的密钥并绑定" class="headerlink" title="3、生成SSH的密钥并绑定"></a>3、生成SSH的密钥并绑定</h2><p>一般正常用GitHub的电脑都没问题，哈哈哈，这一步可以跳过。</p><p>在一个文件夹中打开gitbash，命令行中输入 ssh:ssh-keygen -t rsa -C “邮箱地址”</p><p>.ssh生成路径：C:\Users\自己的用户名.ssh</p><p><strong>可以上来就直接测试。</strong></p><p>测定ssh是否绑定成功：ssh -T <a href="mailto:&#x67;&#x69;&#x74;&#64;&#103;&#105;&#116;&#x68;&#x75;&#x62;&#46;&#99;&#x6f;&#109;">&#x67;&#x69;&#x74;&#64;&#103;&#105;&#116;&#x68;&#x75;&#x62;&#46;&#99;&#x6f;&#109;</a></p><p>如果一直出现ssh: connect to host github.com port 22: Connection refused的话具体看这个教程<a href="https://www.cnblogs.com/Archer314/p/14641310.html">https://www.cnblogs.com/Archer314/p/14641310.html</a> </p><h2 id="4、初始化博客"><a href="#4、初始化博客" class="headerlink" title="4、初始化博客"></a>4、初始化博客</h2><p>新建一个文件夹，选择合适的位置，这就是你日后写博客的本地文件了，进入这个文件后，打开gitbash，输入命令行：</p><p>hexo init      #初始化hexo博客</p><p>如果报错SyntaxError: Unexpected token …</p><p>建议更新一下node.js版本</p><p>hexo s    #静态生成</p><h2 id="5、把本地的博客传到github上，就可以直接当作网站打开了"><a href="#5、把本地的博客传到github上，就可以直接当作网站打开了" class="headerlink" title="5、把本地的博客传到github上，就可以直接当作网站打开了"></a>5、把本地的博客传到github上，就可以直接当作网站打开了</h2><p>配置文件修改(_config.yml)，就在当前文件夹下</p><p><img src="https://raw.githubusercontent.com/LIyvqi/FigOfWeb/main/image-20220612233348720.png" alt="image-20220612233348720"></p><p>（：后面有个空格）</p><p>deploy:</p><p> type: git</p><p> repository: <a href="https://github.com/%E4%BD%A0%E7%9A%84%E5%90%8D%E5%AD%97/%E4%BB%93%E5%BA%93%E7%9A%84%E5%90%8D%E5%AD%97.git">https://github.com/你的名字/仓库的名字.git</a></p><p> branch: 分支</p><p>之后在gitbash命令行中输入：npm install hexo-deployer-git –save</p><p>这样就安装好了hexo-deployer-git自动部署发布工具。</p><p>上述就是使用hexo搭建一个个人博客的教程，自定义域名还要花钱买，我们白嫖了哦，就用这个吧，可以在网络上访问，直接输入 <a href="https://liyvqi.github.io/">https://liyvqi.github.io/</a> </p><h2 id="6、更换主题"><a href="#6、更换主题" class="headerlink" title="6、更换主题"></a>6、更换主题</h2><p>在上面新建的那个web文件夹下，git bash复制命令行下载新的主题以及更新即可。</p><p><img src="https://raw.githubusercontent.com/LIyvqi/FigOfWeb/main/image-20220612233434657.png" alt="image-20220612233434657"></p><p>之后把_config.yml中的theme换成3-hexo</p><p>再之后选择更新：</p><pre><code class="Plain">cd themes/3-hexogit pull</code></pre><p>返回到MyWeb目录之后，输入   hexo server查看本地的主题是否已经换了。</p><p>如果配置了Github之后，可以输入以下命令提交修改后的主题博客。</p><pre><code class="Plain">hexo clean &amp;&amp; hexo g &amp;&amp; hexo d</code></pre><p>我做的时候出线了本地主题换了，但是GitHub上没有，有延迟的问题，等一会儿就好了。</p><h2 id="7、网站内容修改"><a href="#7、网站内容修改" class="headerlink" title="7、网站内容修改"></a>7、网站内容修改</h2><p>更换了主题之后，这个网站的格式内容什么的，都是在下面这个文件夹下</p><p>D:\MyBlog\MyWeb\themes\3-hexo</p><p>一些细节什么的，可以先改_config.yml   里面的注释比较齐全，可以改成自己的了。</p><h2 id="8、发文章和删除文章"><a href="#8、发文章和删除文章" class="headerlink" title="8、发文章和删除文章"></a>8、发文章和删除文章</h2><pre><code class="Plain">hexo new &quot;文章名&quot;找到那个.md文件开始写文章，写完了之后，可以hexo s本地查看，之后直接执行下面命令提交就行。hexo d# 删除的时候，在文件夹里面删了，之后执行hexo d</code></pre><h2 id="9、修改博客的报错问题"><a href="#9、修改博客的报错问题" class="headerlink" title="9、修改博客的报错问题"></a>9、修改博客的报错问题</h2><p>一般更改的时候除了改博客，还改一些别的，这时候会报错（spawn failed），是因为git或者hexo d的时候改变了一些.deploy_git文件下的内容，最简单粗暴的办法就是删了重来。</p><pre><code class="Plain">删除.deploy_git文件夹;输入git config --global core.autocrlf false然后，依次执行：hexo cleanhexo ghexo d</code></pre><h2 id="最后的进阶"><a href="#最后的进阶" class="headerlink" title="最后的进阶"></a>最后的进阶</h2><p><a href="http://yearito.cn/posts/hexo-writing-skills.html#Sublime-Text-3">http://yearito.cn/posts/hexo-writing-skills.html#Sublime-Text-3</a></p><p>写作的教程，可以参考上面</p>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 教程 </tag>
            
            <tag> 建站 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World(作者自带的，感谢作者，就不删啦)</title>
      <link href="/2022/06/12/hello-world/"/>
      <url>/2022/06/12/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre><code class="bash">$ hexo new &quot;My New Post&quot;</code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre><code class="bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre><code class="bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre><code class="bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
